{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93110f5",
   "metadata": {},
   "source": [
    "# Runnables 구조 검토\n",
    "\n",
    "LCEL로 `runnable` 을 생성한 후에는 종종 이를 검사하여 어떤 일이 일어나고 있는지 더 잘 파악하고 싶을 것입니다.\n",
    "\n",
    "이 노트북에서는 이를 수행하는 몇 가지 방법을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4d8cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c76648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH13-LCEL-Advanced\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH13-LCEL-Advanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU faiss-cpu tiktoken\n",
    "\n",
    "# 그래프를 그리기 위한 라이브러리 설치\n",
    "# !pip install -qU grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b3453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    # 텍스트 데이터로부터 FAISS 벡터 저장소를 생성합니다.\n",
    "    [\"Teddy is an AI engineer who loves programming!\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# 벡터 저장소를 기반으로 retriever를 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}  \n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template\n",
    ")  # 템플릿을 기반으로 ChatPromptTemplate을 생성합니다.\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")  # ChatOpenAI 모델을 초기화합니다.\n",
    "\n",
    "# chain 을 생성합니다.\n",
    "chain = (\n",
    "    # 검색 컨텍스트와 질문을 지정합니다.\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt  # 프롬프트를 생성합니다.\n",
    "    | model  # 언어 모델을 실행합니다.\n",
    "    | StrOutputParser()  # 출력 결과를 문자열로 파싱합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebcc63",
   "metadata": {},
   "source": [
    "## 그래프 구성 확인\n",
    "\n",
    "runnable의 그래프를 얻을 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b39c06",
   "metadata": {},
   "source": [
    "`chain.get_graph()` 메서드는 체인의 실행 그래프를 반환합니다.\n",
    "\n",
    "- 이 메서드는 체인의 각 노드와 노드 간의 연결을 나타내는 그래프 객체를 반환합니다.\n",
    "- 그래프의 노드는 체인의 각 단계를 나타내며, 에지(edge)는 단계 간의 데이터 흐름을 나타냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d35d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'31780434e0f24194a34da13131e9983b': Node(id='31780434e0f24194a34da13131e9983b', name='Parallel<context,question>Input', data=<class 'langchain_core.runnables.base.RunnableParallel<context,question>Input'>, metadata=None),\n",
       " '88e8642acb3f4d1f81c454260c123085': Node(id='88e8642acb3f4d1f81c454260c123085', name='Parallel<context,question>Output', data=<class 'langchain_core.utils.pydantic.RunnableParallel<context,question>Output'>, metadata=None),\n",
       " 'b0313f700397496098c0e04b04663007': Node(id='b0313f700397496098c0e04b04663007', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x15a391890>, search_kwargs={}), metadata=None),\n",
       " '08d70f43cb8b4170a77f55f7d6405458': Node(id='08d70f43cb8b4170a77f55f7d6405458', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
       " '2e756d4aec744b9ebf62b60887b7e1c0': Node(id='2e756d4aec744b9ebf62b60887b7e1c0', name='ChatPromptTemplate', data=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}  \\n\\nQuestion: {question}'), additional_kwargs={})]), metadata=None),\n",
       " '2825045c02a44ae7945a1fefcb9714d9': Node(id='2825045c02a44ae7945a1fefcb9714d9', name='ChatOpenAI', data=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x15a57a350>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15a519f50>, root_client=<openai.OpenAI object at 0x16a3bda50>, root_async_client=<openai.AsyncOpenAI object at 0x16aa77110>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), metadata=None),\n",
       " 'be3ed0e9e8e04b2287a558be36856edf': Node(id='be3ed0e9e8e04b2287a558be36856edf', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
       " '0d5dda0a38064bc483eb2d0979229d2f': Node(id='0d5dda0a38064bc483eb2d0979229d2f', name='StrOutputParserOutput', data=<class 'langchain_core.output_parsers.string.StrOutputParserOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인의 그래프에서 노드를 가져옵니다.\n",
    "chain.get_graph().nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa8eedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='9eeca51506314a1186b9c6b50f8f708e', target='e00fcbb6f8074e04a0a81126e2643458', data=None, conditional=False),\n",
       " Edge(source='e00fcbb6f8074e04a0a81126e2643458', target='de1f4e11a91f4aa681863c2e6fb7730a', data=None, conditional=False),\n",
       " Edge(source='9eeca51506314a1186b9c6b50f8f708e', target='fc8f1d3a1dba4c6b901ce620493125e3', data=None, conditional=False),\n",
       " Edge(source='fc8f1d3a1dba4c6b901ce620493125e3', target='de1f4e11a91f4aa681863c2e6fb7730a', data=None, conditional=False),\n",
       " Edge(source='de1f4e11a91f4aa681863c2e6fb7730a', target='ab0aec3f908a408c8ab8c600a4f67456', data=None, conditional=False),\n",
       " Edge(source='ab0aec3f908a408c8ab8c600a4f67456', target='14698cbfe5a641feb00e9319123866e6', data=None, conditional=False),\n",
       " Edge(source='9b2b0558632047b4a7101bb7c4da3747', target='2e225bfbcfe54a3ba4e4b610f6219b4e', data=None, conditional=False),\n",
       " Edge(source='14698cbfe5a641feb00e9319123866e6', target='9b2b0558632047b4a7101bb7c4da3747', data=None, conditional=False)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인의 그래프에서 엣지를 가져옵니다.\n",
    "chain.get_graph().edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69801031",
   "metadata": {},
   "source": [
    "## 그래프 출력\n",
    "\n",
    "그래프를 출력하면 이해하기 쉬운 형태로 표현할 수 있습니다.\n",
    "\n",
    "비록 출력 결과가 매우 읽기 쉽지는 않지만, 출력을 통해 보다 이해하기 쉬운 형태로 그래프를 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22c179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<context,question>Input |         \n",
      "           +---------------------------------+         \n",
      "                    **               **                \n",
      "                 ***                   ***             \n",
      "               **                         **           \n",
      "+----------------------+              +-------------+  \n",
      "| VectorStoreRetriever |              | Passthrough |  \n",
      "+----------------------+              +-------------+  \n",
      "                    **               **                \n",
      "                      ***         ***                  \n",
      "                         **     **                     \n",
      "           +----------------------------------+        \n",
      "           | Parallel<context,question>Output |        \n",
      "           +----------------------------------+        \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                  +--------------------+               \n",
      "                  | ChatPromptTemplate |               \n",
      "                  +--------------------+               \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                      +------------+                   \n",
      "                      | ChatOpenAI |                   \n",
      "                      +------------+                   \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "# 체인의 그래프를 ASCII 형식으로 출력합니다.\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a6d11",
   "metadata": {},
   "source": [
    "## 프롬프트 가져오기\n",
    "\n",
    "체인에서 중요한 부분은 사용되는 프롬프트입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba41b1c",
   "metadata": {},
   "source": [
    "`chain.get_prompts()` 메서드는 체인에서 사용되는 프롬프트(prompt) 객체의 리스트를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8deea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}  \\n\\nQuestion: {question}'), additional_kwargs={})])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.get_prompts()  # 체인에서 사용되는 프롬프트를 가져옵니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr--Xj_wIV7-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
