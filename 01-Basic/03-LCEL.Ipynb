{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 예시: 프롬프트 + 모델 + 출력 파서\n",
    "\n",
    "- 가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 함께 연결하는 것입니다. \n",
    "- 이것이 어떻게 작동하는지 보기 위해, 각 나라별 수도를 물어보는 Chain을 생성해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿의 활용\n",
    "\n",
    "`PromptTemplate`\n",
    "\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\n",
    "- 사용법\n",
    "  - `template`: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 `{}`는 변수를 나타냅니다.\n",
    "  - `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\n",
    "\n",
    "`input_variables`\n",
    "\n",
    "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_template()` 메소드를 사용하여 PromptTemplate 객체 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain 생성\n",
    "\n",
    "- 파이프라인 == Chain\n",
    "\n",
    "### LCEL(LangChain Expression Language)\n",
    "\n",
    "![lcel.png](./images/lcel.png)\n",
    "\n",
    "여기서 우리는 LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합합니다\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "`|` 기호는 [unix 파이프 연산자](<https://en.wikipedia.org/wiki/Pipeline_(Unix)>)와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달합니다.\n",
    "\n",
    "이 체인에서 사용자 입력은 프롬프트 템플릿으로 전달되고, 그런 다음 프롬프트 템플릿 출력은 모델로 전달됩니다. 각 구성 요소를 개별적으로 살펴보면 무슨 일이 일어나고 있는지 이해할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 {how} 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 프롬프트 결과가 모델로 자동 전달됨\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['how', 'topic'], input_types={}, partial_variables={}, template='{topic} 에 대해 {how} 설명해주세요.')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x16db95410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x16dba1250>, root_client=<openai.OpenAI object at 0x16db85c50>, root_async_client=<openai.AsyncOpenAI object at 0x16db955d0>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoke() 호출\n",
    "\n",
    "- python 딕셔너리 형태로 입력값을 전달합니다.(키: 값)\n",
    "- invoke() 함수 호출 시, 입력값을 전달합니다.\n",
    "- 답변이 완성될때까지 기다렸다가 한 번에 호출됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\n",
    "    \"topic\": \"인공지능 모델의 학습 원리\",\n",
    "    \"how\": \"3줄로\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델은 데이터를 입력으로 받아 가중치를 조정하고, 손실 함수를 최소화하는 방향으로 학습합니다. 학습 과정에서 모델은 입력 데이터와 정답 레이블을 비교하여 오차를 계산하고, 역전파 알고리즘을 통해 가중치를 업데이트합니다. 이러한 과정을 반복하여 모델이 데이터 패턴을 학습하고 예측을 수행할 수 있게 됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 148, 'prompt_tokens': 34, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-426e6879-5d3c-466d-90cc-127440730c5d-0', usage_metadata={'input_tokens': 34, 'output_tokens': 148, 'total_tokens': 182, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 스트리밍을 출력하는 예시 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델은 데이터를 입력하고 목표값과 비교하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 가중치를 조정하면서 학습합니다. 이 과정을 반복하여 모델이 데이터에 대해 더 잘 일반화되도록 학습합니다. 학습이 끝나면 모델은 새로운 데이터에 대해 예측을 할 수 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력파서(Output Parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain 에 출력파서를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하고 예측하는 과정을 말합니다. 모델은 입력 데이터를 특정한 방식으로 처리하여 출력을 생성하고, 이때 발생하는 오차를 최소화하도록 학습합니다. 학습 과정은 반복적으로 이루어지며, 모델은 오차를 줄이기 위해 가중치와 편향을 조절하면서 최적의 성능을 찾아나갑니다. 이렇게 모델은 데이터를 효율적으로 학습하여 새로운 데이터에 대해 정확한 예측을 할 수 있도록 되는 것이 인공지능 모델의 핵심 원리입니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\", \"how\": \"쉽게\"}\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 통해 패턴을 학습하는 과정입니다. 먼저 모델은 입력 데이터를 받아들이고, 이 데이터를 특정한 방식으로 처리하여 출력을 생성합니다. 이때 모델은 정답과 비교하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 가중치와 편향을 조정하면서 학습합니다. 이 과정을 반복하면 모델은 점차 데이터의 패턴을 학습하게 되고, 정확한 결과를 예측할 수 있게 됩니다. 이렇게 학습된 모델은 새로운 데이터에 대해 예측을 할 수 있게 되며, 이를 통해 다양한 문제를 해결할 수 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 템플릿을 변경하여 적용\n",
    "\n",
    "- 아래의 프롬프트 내용을 얼마든지 **변경** 하여 테스트 해볼 수 있습니다.\n",
    "- `model_name` 역시 변경하여 테스트가 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  - Server: Hello! Welcome to our restaurant. How many people are in your party?\n",
      "  - You: Hi! It's just me today.\n",
      "  - Server: Great! Please follow me to your table. Here's the menu. Can I get you something to drink while you decide?\n",
      "  - You: Yes, I would like a glass of water, please.\n",
      "  - Server: Sure, I'll be right back with your water. Take your time with the menu.\n",
      "  - (A few minutes later)\n",
      "  - Server: Here’s your water. Have you decided what you’d like to order?\n",
      "  - You: Yes, I’ll have the grilled chicken with a side of vegetables, please.\n",
      "  - Server: Excellent choice! Would you like any appetizers or desserts today?\n",
      "  - You: No, thank you. Just the main course.\n",
      "  - Server: Alright, your order will be ready shortly. Enjoy your meal!\n",
      "\n",
      "- 한글 해석:\n",
      "  - 종업원: 안녕하세요! 저희 식당에 오신 것을 환영합니다. 몇 분이세요?\n",
      "  - 당신: 안녕하세요! 오늘은 저 혼자입니다.\n",
      "  - 종업원: 좋습니다! 테이블로 안내해 드릴게요. 여기 메뉴입니다. 메뉴를 보시는 동안 음료를 가져다 드릴까요?\n",
      "  - 당신: 네, 물 한 잔 주세요.\n",
      "  - 종업원: 네, 물 바로 가져다 드리겠습니다. 메뉴 천천히 보세요.\n",
      "  - (몇 분 후)\n",
      "  - 종업원: 여기 물입니다. 주문하실 준비 되셨나요?\n",
      "  - 당신: 네, 구운 치킨과 야채 곁들임으로 주세요.\n",
      "  - 종업원: 좋은 선택입니다! 오늘 에피타이저나 디저트도 드시겠어요?\n",
      "  - 당신: 아뇨, 감사합니다. 메인 코스만 주세요.\n",
      "  - 종업원: 알겠습니다, 주문하신 음식 곧 준비해 드릴게요. 맛있게 드세요!\n"
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  - Waiter: Good evening! Welcome to our restaurant. How many people are in your party?\n",
      "  - Customer: Good evening! It's just me today.\n",
      "  - Waiter: Great, please follow me to your table. Here's the menu. Can I get you something to drink to start with?\n",
      "  - Customer: Yes, I'll have a glass of water, please.\n",
      "  - Waiter: Certainly. Are you ready to order, or would you like a few more minutes?\n",
      "  - Customer: I'm ready to order. I'll have the grilled chicken with a side of mashed potatoes.\n",
      "  - Waiter: Excellent choice. Would you like any appetizers or desserts with that?\n",
      "  - Customer: No, thank you. Just the main course for now.\n",
      "  - Waiter: Perfect. Your order will be ready shortly. Enjoy your meal!\n",
      "\n",
      "- 한글 해석:\n",
      "  - 웨이터: 안녕하세요! 저희 레스토랑에 오신 것을 환영합니다. 몇 분이신가요?\n",
      "  - 손님: 안녕하세요! 오늘은 저 혼자입니다.\n",
      "  - 웨이터: 좋습니다, 저를 따라 테이블로 오세요. 여기 메뉴입니다. 시작으로 음료를 드릴까요?\n",
      "  - 손님: 네, 물 한 잔 주세요.\n",
      "  - 웨이터: 알겠습니다. 주문할 준비가 되셨나요? 아니면 몇 분 더 필요하신가요?\n",
      "  - 손님: 주문할 준비가 됐어요. 그릴드 치킨과 매쉬드 포테이토를 주세요.\n",
      "  - 웨이터: 좋은 선택이세요. 전채나 디저트를 추가하시겠어요?\n",
      "  - 손님: 아니요, 괜찮습니다. 일단 메인 코스만 주세요.\n",
      "  - 웨이터: 알겠습니다. 잠시 후에 음식을 가져다 드리겠습니다. 맛있게 드세요!"
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  - Customer: Hi, I'd like to order a pizza for delivery, please.\n",
      "  - Employee: Sure! What size pizza would you like?\n",
      "  - Customer: I'll have a large pizza.\n",
      "  - Employee: Great choice. What toppings would you like on your pizza?\n",
      "  - Customer: Could I get pepperoni, mushrooms, and extra cheese?\n",
      "  - Employee: Absolutely. Would you like any sides or drinks with that?\n",
      "  - Customer: Yes, I’ll take a side of garlic bread and a bottle of cola.\n",
      "  - Employee: Perfect. Can I have your address and phone number for the delivery?\n",
      "  - Customer: Sure, my address is 123 Main Street, and my phone number is 555-0123.\n",
      "  - Employee: Thank you. Your total comes to $25.99. It should arrive in about 30 minutes.\n",
      "  - Customer: Sounds good! Thank you very much.\n",
      "  - Employee: You're welcome! Have a great day!\n",
      "\n",
      "- 한글 해석:\n",
      "  - 고객: 안녕하세요, 피자를 배달 주문하고 싶습니다.\n",
      "  - 직원: 네! 어떤 사이즈의 피자를 원하시나요?\n",
      "  - 고객: 큰 사이즈로 주세요.\n",
      "  - 직원: 좋은 선택입니다. 피자에 어떤 토핑을 원하시나요?\n",
      "  - 고객: 페퍼로니, 버섯, 그리고 치즈 추가해 주세요.\n",
      "  - 직원: 물론입니다. 사이드나 음료 추가하시겠어요?\n",
      "  - 고객: 네, 마늘빵 하나랑 콜라 한 병 주세요.\n",
      "  - 직원: 알겠습니다. 배달을 위해 주소와 전화번호를 알려주시겠어요?\n",
      "  - 고객: 네, 주소는 메인 스트리트 123번지이고, 전화번호는 555-0123입니다.\n",
      "  - 직원: 감사합니다. 총 금액은 $25.99입니다. 약 30분 후에 도착할 예정입니다.\n",
      "  - 고객: 좋아요! 감사합니다.\n",
      "  - 직원: 감사합니다! 좋은 하루 되세요!"
     ]
    }
   ],
   "source": [
    "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-0L6nEhsY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
