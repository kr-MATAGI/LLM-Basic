{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f09671e",
   "metadata": {},
   "source": [
    "# GPT4All\n",
    "\n",
    "[GPT4All](https://gpt4all.io/index.html)은 무료로 사용할 수 있는 로컬 실행 기반의 개인정보 보호를 고려한 챗봇입니다.\n",
    "\n",
    "GPU나 인터넷 연결이 필요하지 않으며, GPT4All Falcon, Wizard 등 인기 있는 모델과 자체 모델을 제공합니다.\n",
    "\n",
    "이 노트북에서는 LangChain과 함께 [GPT4All embeddings](https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All)를 사용하는 방법을 설명합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9994d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855f6c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH08-Embeddings\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH08-Embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce0b701",
   "metadata": {},
   "source": [
    "## GPT4All의 Python 바인딩 설치\n",
    "\n",
    "GPT4All의 Python 바인딩을 설치하려면 다음 명령을 실행하세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU  gpt4all > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2042f",
   "metadata": {},
   "source": [
    "- `GPT4AllEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.\n",
    "\n",
    "`GPT4AllEmbeddings`는 GPT4All 모델을 사용하여 텍스트 데이터를 벡터로 임베딩하는 기능을 제공하는 클래스입니다. 이 클래스는 LangChain 프레임워크의 임베딩 인터페이스를 구현하여, LangChain의 다양한 기능과 함께 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c687401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456df15",
   "metadata": {},
   "source": [
    "GPT4All은 CPU에 최적화된 대조 학습 문장 변환기를 사용하여 임의 길이의 텍스트 문서에 대한 고품질 임베딩 생성을 지원합니다. 이러한 임베딩은 OpenAI를 사용하는 많은 작업에서 품질이 비슷합니다.\n",
    "\n",
    "`GPT4AllEmbeddings` 클래스의 인스턴스를 생성합니다.\n",
    "\n",
    "- `GPT4AllEmbeddings`는 GPT4All 모델을 사용하여 텍스트 데이터를 벡터로 변환하는 임베딩 모델입니다.\n",
    "- 이 코드에서는 `gpt4all_embd` 변수에 `GPT4AllEmbeddings` 인스턴스를 할당합니다.\n",
    "- 이후 `gpt4all_embd`를 사용하여 텍스트 데이터를 벡터로 변환할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1998cdf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/matagi/anaconda3/envs/teddy/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllmodel.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt4all_embd \u001b[38;5;241m=\u001b[39m \u001b[43mGPT4AllEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# GPT4All 임베딩 객체를 생성합니다.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/teddy/lib/python3.11/site-packages/langchain_community/embeddings/gpt4all.py:38\u001b[0m, in \u001b[0;36mGPT4AllEmbeddings.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate that GPT4All library is installed.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt4all\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embed4All\n\u001b[1;32m     40\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Embed4All(\n\u001b[1;32m     41\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     42\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     43\u001b[0m         device\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(values\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4all_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/teddy/lib/python3.11/site-packages/gpt4all/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt4all\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CancellationError \u001b[38;5;28;01mas\u001b[39;00m CancellationError, Embed4All \u001b[38;5;28;01mas\u001b[39;00m Embed4All, GPT4All \u001b[38;5;28;01mas\u001b[39;00m GPT4All\n",
      "File \u001b[0;32m~/anaconda3/envs/teddy/lib/python3.11/site-packages/gpt4all/gpt4all.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IncompleteRead, ProtocolError\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pyllmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (CancellationError \u001b[38;5;28;01mas\u001b[39;00m CancellationError, EmbCancelCallbackType, EmbedResult \u001b[38;5;28;01mas\u001b[39;00m EmbedResult,\n\u001b[1;32m     24\u001b[0m                          LLModel, ResponseCallbackType, empty_response_callback)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Self, TypeAlias\n",
      "File \u001b[0;32m~/anaconda3/envs/teddy/lib/python3.11/site-packages/gpt4all/_pyllmodel.py:91\u001b[0m\n\u001b[1;32m     86\u001b[0m         lib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(\u001b[38;5;28mstr\u001b[39m(MODEL_LIB_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllmodel.dll\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[0;32m---> 91\u001b[0m llmodel \u001b[38;5;241m=\u001b[39m \u001b[43mload_llmodel_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLLModelPromptContext\u001b[39;00m(ctypes\u001b[38;5;241m.\u001b[39mStructure):\n\u001b[1;32m     95\u001b[0m     _fields_ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     96\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_int32)),\n\u001b[1;32m     97\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, ctypes\u001b[38;5;241m.\u001b[39mc_size_t),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_erase\u001b[39m\u001b[38;5;124m\"\u001b[39m, ctypes\u001b[38;5;241m.\u001b[39mc_float),\n\u001b[1;32m    109\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/teddy/lib/python3.11/site-packages/gpt4all/_pyllmodel.py:81\u001b[0m, in \u001b[0;36mload_llmodel_library\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m ext \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdylib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinux\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mso\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdll\u001b[39m\u001b[38;5;124m\"\u001b[39m}[platform\u001b[38;5;241m.\u001b[39msystem()]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# macOS, Linux, MinGW\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     lib \u001b[38;5;241m=\u001b[39m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMODEL_LIB_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibllmodel.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdll\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/teddy/lib/python3.11/ctypes/__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/matagi/anaconda3/envs/teddy/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllmodel.so)"
     ]
    }
   ],
   "source": [
    "gpt4all_embd = GPT4AllEmbeddings()  # GPT4All 임베딩 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602cb47",
   "metadata": {},
   "source": [
    "- `text` 변수에 \"임베딩 테스트를 하기 위한 샘플 문장입니다.\" 라는 문자열을 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"임베딩 테스트를 하기 위한 샘플 문장입니다.\"  # 테스트용 문서 텍스트를 정의합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc286dd",
   "metadata": {},
   "source": [
    "## Embed the Textual Data\n",
    "\n",
    "텍스트 데이터를 임베딩하는 과정은 다음과 같습니다.\n",
    "\n",
    "먼저, 텍스트 데이터를 토큰화하여 숫자 형태로 변환합니다.\n",
    "\n",
    "이때, 사전 학습된 토크나이저(tokenizer)를 활용하여 텍스트를 토큰 단위로 분리하고, 각 토큰을 고유한 정수로 매핑합니다.\n",
    "\n",
    "다음으로, 토큰화된 데이터를 임베딩 레이어에 입력하여 고차원의 밀집 벡터(dense vector) 형태로 변환합니다.\n",
    "\n",
    "이 과정에서 각 토큰은 해당 토큰의 의미와 문맥을 포착하는 실수 값들의 벡터로 표현됩니다.\n",
    "\n",
    "마지막으로, 임베딩된 벡터는 다양한 자연어 처리 작업에 활용될 수 있습니다.\n",
    "\n",
    "예를 들어, 문서 분류, 감성 분석, 기계 번역 등의 작업에서 입력 데이터로 사용되어 모델의 성능을 향상시킬 수 있습니다.\n",
    "\n",
    "이러한 텍스트 데이터 임베딩 과정은 자연어 처리 분야에서 매우 중요한 역할을 하며, 대량의 텍스트 데이터를 효과적으로 처리하고 분석하는 데 필수적입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d497f9e5",
   "metadata": {},
   "source": [
    "`gpt4all_embd` 객체의 `embed_query` 메서드를 사용하여 주어진 텍스트(`text`)를 임베딩합니다.\n",
    "\n",
    "- `text` 변수에 임베딩할 텍스트가 저장되어 있습니다.\n",
    "- `gpt4all_embd` 객체는 GPT4All 모델을 사용하여 텍스트 임베딩을 수행하는 객체입니다.\n",
    "- `embed_query` 메서드는 주어진 텍스트를 벡터 형태로 변환하여 반환합니다.\n",
    "- 임베딩 결과는 `query_result` 변수에 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = gpt4all_embd.embed_query(\n",
    "    text\n",
    ")  # 주어진 텍스트에 대한 쿼리 임베딩을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a35a6e",
   "metadata": {},
   "source": [
    "embed_documents 함수를 사용하면 여러 개의 텍스트 조각을 임베딩할 수 있습니다.\n",
    "\n",
    "또한 이러한 임베딩을 Nomic의 Atlas(https://docs.nomic.ai/index.html)와 매핑하여 데이터의 시각적 표현을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51866a",
   "metadata": {},
   "source": [
    "임베딩된 차원의 크기를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5baf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩된 차원의 크기를 확인합니다.\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09a0f7",
   "metadata": {},
   "source": [
    "`gpt4all_embd` 객체의 `embed_documents` 메서드를 사용하여 `text` 문서를 임베딩합니다.\n",
    "\n",
    "- `text` 문서를 리스트로 감싸서 `embed_documents` 메서드의 인자로 전달합니다.\n",
    "- `embed_documents` 메서드는 문서의 임베딩 벡터를 계산하여 반환합니다.\n",
    "- 반환된 임베딩 벡터는 `doc_result` 변수에 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 텍스트를 임베딩하여 문서 벡터를 생성합니다.\n",
    "doc_result = gpt4all_embd.embed_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cf5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩된 차원의 크기를 확인합니다.\n",
    "len(doc_result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
